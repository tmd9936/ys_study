test <- newdata[-datatotal,]
ctrl <- trainControl(method="repeatedcv", repeats = 5)
nbFit <- train(target ~ .,
data = train,
method ="naive_bayes",
trControl = ctrl,
metric="Accuracy")
# Factor Data
table(rawdata$job)
# Factor Data
prop.table(table(rawdata$job))
# Factor Data
barplot(prop.table(table(rawdata$job)), main="jop proportion" )
pie(prop.table(table(rawdata$job)), main="jop proportion" )
pie(sort(prop.table(table(rawdata$job))), main="jop proportion" )
source('C:/study/ys_study/R_lang/demo_19_practice.R', encoding = 'UTF-8', echo=TRUE)
# Factor Data
par(mfrow=c(4,3), mar=c(5,4,4,2))
barplot(prop.table(table(rawdata$job)), main="jop proportion" )
barplot(prop.table(table(rawdata$marital)), main="marital proportion" )
barplot(prop.table(table(rawdata$education)), main="education proportion" )
barplot(prop.table(table(rawdata$default)), main="default proportion" )
barplot(prop.table(table(rawdata$housing)), main="housing proportion" )
barplot(prop.table(table(rawdata$loan)), main="loan proportion" )
barplot(prop.table(table(rawdata$contact)), main="contact proportion" )
barplot(prop.table(table(rawdata$month)), main="month proportion" )
barplot(prop.table(table(rawdata$day_of_week)), main="day_of_week proportion" )
barplot(prop.table(table(rawdata$poutcome)), main="poutcome proportion" )
barplot(prop.table(table(rawdata$target)), main="target proportion" )
# 전처리
## 결측치 처리 (컴퓨팅 환경에 따라 아예 지워버리는게 나을 수 있음..)
library(caret)
rawdata <- read.csv("financial_marketing.csv", header = T)
# unknown -> NA
rawdata[rawdata=="unknown"] <- NA
# na로 바꾸기
sum(is.na(rawdata))
# na omit -> na 데이터 지우기
rawdata <- na.omit(rawdata)
# categotical Data pie
par(mfrow=c(4,3), mar=c(5,4,4,2))
pie(prop.table(table(rawdata$job)), main="jop proportion" )
pie(prop.table(table(rawdata$marital)), main="marital proportion" )
pie(prop.table(table(rawdata$education)), main="education proportion" )
pie(prop.table(table(rawdata$default)), main="default proportion" )
pie(prop.table(table(rawdata$housing)), main="housing proportion" )
pie(prop.table(table(rawdata$loan)), main="loan proportion" )
pie(prop.table(table(rawdata$contact)), main="contact proportion" )
pie(prop.table(table(rawdata$month)), main="month proportion" )
pie(prop.table(table(rawdata$day_of_week)), main="day_of_week proportion" )
pie(prop.table(table(rawdata$poutcome)), main="poutcome proportion" )
pie(prop.table(table(rawdata$target)), main="target proportion" )
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
metric="Accuracy")
rawdata <- read.csv("financial_marketing.csv", header = T)
# unknown -> NA
rawdata[rawdata=="unknown"] <- NA
# na로 바꾸기
sum(is.na(rawdata))
# na omit -> na 데이터 지우기
rawdata <- na.omit(rawdata)
str(rawdata)
# 문자가 들어간 feature의 처리
rawdata$job = as.factor(rawdata$job)
rawdata$marital = as.factor(rawdata$marital)
rawdata$education = as.factor(rawdata$education)
rawdata$default = as.factor(rawdata$default)
rawdata$housing = as.factor(rawdata$housing)
rawdata$loan = as.factor(rawdata$loan)
rawdata$contact = as.factor(rawdata$contact)
rawdata$month = as.factor(rawdata$month)
rawdata$day_of_week = as.factor(rawdata$day_of_week)
rawdata$poutcome = as.factor(rawdata$poutcome)
rawdata$target = as.factor(rawdata$target)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale")
metric="Accuracy")
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
# na로 바꾸기
sum(is.na(rawdata))
str(rawdata)
set.seed(2020)
newdata <- rawdata
datatotal <- sort(sample(nrow(newdata), nrow(newdata)*.7))
train <- newdata[datatotal,]
test <- newdata[-datatotal,]
ctrl <- trainControl(method="repeatedcv", repeats = 5)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="RMSE")
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
str(rawdata)
rawdata <- data.frame(rawdata)
set.seed(2020)
newdata <- rawdata
datatotal <- sort(sample(nrow(newdata), nrow(newdata)*.7))
train <- newdata[datatotal,]
test <- newdata[-datatotal,]
ctrl <- trainControl(method="repeatedcv", repeats = 5)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
str(rawdata)
rawdata <- read.csv("financial_marketing.csv", header = T)
# unknown -> NA
rawdata[rawdata=="unknown"] <- NA
# na로 바꾸기
sum(is.na(rawdata))
# na omit -> na 데이터 지우기
rawdata <- na.omit(rawdata)
rawdata <- data.frame(rawdata)
set.seed(2020)
newdata <- rawdata
datatotal <- sort(sample(nrow(newdata), nrow(newdata)*.7))
train <- newdata[datatotal,]
test <- newdata[-datatotal,]
ctrl <- trainControl(method="repeatedcv", repeats = 5)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
str(rawdata)
# 문자가 들어간 feature의 처리
rawdata$job = as.factor(rawdata$job)
rawdata$marital = as.factor(rawdata$marital)
rawdata$education = as.factor(rawdata$education)
rawdata$default = as.factor(rawdata$default)
rawdata$housing = as.factor(rawdata$housing)
rawdata$loan = as.factor(rawdata$loan)
rawdata$contact = as.factor(rawdata$contact)
rawdata$month = as.factor(rawdata$month)
rawdata$day_of_week = as.factor(rawdata$day_of_week)
rawdata$poutcome = as.factor(rawdata$poutcome)
rawdata$target = as.factor(rawdata$target)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
# factor 대조군이 1개만 있는 컬럼 삭제
rawdata[,"default"] <- NULL
str(rawdata)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
# factor 대조군이 1개만 있는 컬럼 삭제
rawdata[,"default"] <- NULL
str(rawdata)
set.seed(2020)
newdata <- rawdata
datatotal <- sort(sample(nrow(newdata), nrow(newdata)*.7))
train <- newdata[datatotal,]
test <- newdata[-datatotal,]
ctrl <- trainControl(method="repeatedcv", repeats = 5)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
str(newdata)
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
preProcess = c("center","scale"),
metric="Accuracy")
# 로지스틱 회귀분석
logistic_Fit <- train(target ~ .,
data = train,
method ="regLogistic",
trControl = ctrl,
metric="Accuracy")
lmt_Fit
logistic_Fit
plot(logistic_Fit)
logistic_pred = predict(logistic_Fit, newdata = test)
confusionMatrix(logistic_pred, test$target)
importance_logit <- varImp(logistic_Fit, scale=F)
plot(importance_logit)
# Boosted 로지스틱
boosted_Fit <- train(target ~ .,
data = train,
method ="LogitBoost",
trControl = ctrl,
metric="Accuracy")
boosted_Fit
plot(boosted_Fit)
boosted_pred = predict(boosted_Fit, newdata = test)
confusionMatrix(boosted_pred, test$target)
# 로지스틱 모형트리 (LMT)
lmt_Fit <- train(target ~ .,
data = train,
method ="LMT",
trControl = ctrl,
metric="Accuracy")
lmt_Fit
plot(lmt_Fit)
lmt_pred = predict(lmt_Fit, newdata = test)
confusionMatrix(lmt_pred, test$target)
# Penalized 로지스틱
plr_fit <- train(target ~ .,
data = train,
method ="plr",
trControl = ctrl,
metric="Accuracy")
# 나이브 베이즈
nb_fit <- train(target ~ .,
data = train,
method ="nb",
trControl = ctrl,
metric="Accuracy")
# 나이브 베이즈
nb_fit <- train(target ~ .,
data = train,
method ="naive_bayes",
trControl = ctrl,
metric="Accuracy")
nb_fit
plot(nb_fit)
nb_pred = predict(nb_fit, newdata = test)
confusionMatrix(nb_pred, test$target)
# 랜덤포레스트
rf_fit <- train(target ~ .,
data = train,
method ="rf",
trControl = ctrl,
metric="Accuracy")
rf_fit
plot(rf_fit)
rf_pred = predict(rf_fit, newdata = test)
confusionMatrix(rf_pred, test$target)
# 서포트 벡터머신
lin_fit <- train(target ~ .,
data = train,
method ="svmLinear",
trControl = ctrl,
metric="Accuracy")
lin_fit
plot(lin_fit)
lin_pred = predict(lin_fit, newdata = test)
confusionMatrix(lin_pred, test$target)
# 커널 서포트 벡터 머신
poly_fit <- train(target ~ .,
data = train,
method ="svmPoly",
trControl = ctrl,
metric="Accuracy")
# 데이터터
iris
head(iris)
str(iris)
#
colsums(is.na(iris))
# 데이터 파악하기
# sepal 꽃받침
# petal 꽃잎
# Species 품좀
iris
head(iris)
str(iris)
#
colums(is.na(iris))
#
colSums(is.na(iris))
summary(iris)
boxplot(iris)
## 주성분 분석하기
# procomp 함수 적용하기(평균:0, 분산:1)
iris.pca <- procomp(iris[1:4], center = T, scale=T)
## 주성분 분석하기
# prcomp 함수 적용하기(평균:0, 분산:1)
iris.pca <- prcomp(iris[1:4], center = T, scale=T)
iris.pca
iris.pca
iris.pca
# 데이터 파악하기
# sepal 꽃받침
# petal 꽃잎
# Species 품좀
iris
## 주성분 분석하기
# prcomp 함수 적용하기(평균:0, 분산:1)
iris.pca <- prcomp(iris[1:4], center = T, scale=T)
iris.pca
summary(isis.pca)
summary(iris.pca)
iris.pca$rotation
iris.pca$x
head(iris.pca$x, 10)
plot(iris.pca, type='l', main = 'Scree plot')
# 2개의 차원으로 축소
head(iris.pcs$x[,1:2])
# 2개의 차원으로 축소
head(iris.pca$x[,1:2])
# 2개의 차원으로 축소
head(iris.pca$x[,1:2], 10)
# 2차원 시각화
library(ggfortify)
# 2차원 시각화
install.packages("ggfortify")
library(ggfortify)
autoplot(iris.pca, data=iris, colour='Species')
autoplot(iris.pca[,1:2], data=iris, colour='Species')
autoplot(iris.pca[,1:2], data=iris, colour='Species')
autoplot(iris.pca$x[,1:2], data=iris, colour='Species')
autoplot(iris.pca, data=iris, colour='Species')
# 2개의 차원으로 축소
head(iris.pca$x[,1:2], 10)
plot(iris.pca, type='l', main = 'Scree plot')
# 차원 축소를 했을때 각 변수가 갖는 값
# 새로운 축에서 그 데이터들이 갖는 값 (각 주성분들의 값)
head(iris.pca$x, 10)
head(iris)
autoplot(iris.pca, data=iris, colour='Species')
str(iris)
install.packages("jpeg")
library(jpeg)
dog <- redJPEG('dog.jpg')
dog <- readJPEG('dog.jpg')
class(dog)
str(dog)
head(dog)
dim(dog)
dog <- readJPEG('dog.jpg')
dim(dog)
r <- dog[,,1]
g <- dog[,,2]
b <- dog[,,3]
# r,g,b각각 차원축소를 하고 합치기
dog.r.pca <- prcomp(r, center = F,)
dog.g.pca <- prcomp(g, center = F,)
dog.b.pca <- prcomp(b, center = F,)
rgb.pca <- list(dog.r.pca, dog.g.pac, dog.b.pca)
rgb.pca <- list(dog.r.pca, dog.g.pca, dog.b.pca)
pca.img <- sapply(rgb.pca, function(j) {
compressed.img <- j$x[1:i] %*% t(j$rotation[,l:i])
}, simplify = 'array')
compressed.img <- j$x[1:i] %*% t(j$rotation[,1:i])
compressed.img <- j$x[,1:i] %*% t(j$rotation[,1:i])
# 축소할 차원 수
pc <- c(2, 10, 50, 100, 300)
for(i in pc) {
pca.img <- sapply(rgb.pca, function(j) {
compressed.img <- j$x[,1:i] %*% t(j$rotation[,1:i])
}, simplify = 'array')
writeJPEG(pca.img, paste('dog_pca_',i,'.jpg', sep = ''))
}
# 전처리
## 결측치 처리 (컴퓨팅 환경에 따라 아예 지워버리는게 나을 수 있음..)
library(caret)
rawdata <- read.csv("financial_marketing.csv", header = T)
str(rawdata)
rawdata <- read.csv("financial_marketing.csv", header = T)
numdata <- rawdata[,15:19]
str(numdata)
numdata.pca <- prcomp(numdata, center=T, scale=T)
str(numdata.pca)
numdata.pca$rotation
plot(numdata.pca, type="l", main="plot")
library(ggfortify)
autoplot(numdata.pca, data=numdata, colour='Species')
numdata <- rawdata[,15:20]
numdata.pca <- prcomp(numdata, center=T, scale=T)
str(numdata.pca)
numdata.pca$rotation
str(numdata.pca)
str(numdata)
autoplot(numdata.pca, data=numdata, colour='target')
numdata.pca$rotation
summary(numdata.pca)
str(numdata)
# 상관계수
cor(numdata[1:5])
num_feature <- c("age", "duration", "capaign", "previous", "emp.var.rate", "cons.price.idx",
"cons.conf.idx", "euribor3m", "nr.employed")
num_data <- rawdata1[, num_feature]
pca_num <- prcomp(num_data)
plot(pca_num, type="l", main="P")
summary(pca_num)
rawdata1 <- read.csv("financial_marketing.csv", header = T)
num_feature <- c("age", "duration", "capaign", "previous", "emp.var.rate", "cons.price.idx",
"cons.conf.idx", "euribor3m", "nr.employed")
num_data <- rawdata1[, num_feature]
rawdata1 <- read.csv("financial_marketing.csv", header = T)
num_feature <- c("age", "duration", "capaign", "previous", "emp.var.rate", "cons.price.idx",
"cons.conf.idx", "euribor3m", "nr.employed")
num_data <- rawdata1[, num_feature]
rawdata1 <- read.csv("financial_marketing.csv", header = T)
# unknown -> NA
rawdata1[rawdata1 =="unknown"] <- NA
# na로 바꾸기
sum(is.na(rawdata1))
# na omit -> na 데이터 지우기
rawdata1 <- na.omit(rawdata1)
rawdata1 <- data.frame(rawdata1)
rawdata$age <- scale(rawdata$age)
rawdata$duration <- scale(rawdata$duration)
rawdata$campaign <- scale(rawdata$campaign)
rawdata$previous <- scale(rawdata$previous)
rawdata$emp.var.rate <- scale(rawdata$emp.var.rate)
rawdata$cons.price.idx <- scale(rawdata$cons.price.idx)
rawdata$cons.conf.idx <- scale(rawdata$cons.conf.idx)
rawdata$euribor3m <- scale(rawdata$euribor3m)
rawdata$nr.employed <- scale(rawdata$nr.employed)
num_feature <- c("age", "duration", "capaign", "previous", "emp.var.rate", "cons.price.idx",
"cons.conf.idx", "euribor3m", "nr.employed")
num_data <- rawdata1[, num_feature]
num_data <- rawdata1[, num_feature]
num_feature <- c("age", "duration", "campaign", "previous", "emp.var.rate", "cons.price.idx","cons.conf.idx", "euribor3m", "nr.employed")
num_data <- rawdata1[, num_feature]
pca_num <- prcomp(num_data)
plot(pca_num, type="l", main="P")
summary(pca_num)
pca_matrix <- pca_num$ratation
pca_data <- as.matrix(num_data) %*% pca_matrix
pca_matrix <- pca_num$rotation
pca_data <- as.matrix(num_data) %*% pca_matrix
dim(pca_data)
autoplot(pca_num, data=rawdata1, colour='target')
pca_matrix
as.matrix(num_data)
pca_data <- as.matrix(num_data) %*% t(pca_matrix)
dim(pca_data)
autoplot(pca_num, data=rawdata1, colour='target')
pca_matrix <- pca_num$rotation
pca_data <- as.matrix(num_data) %*% t(pca_matrix)
autoplot(pca_num, data=rawdata1, colour='target')
compressed.img <- j$x[,1:i] %*% j$rotation[,1:i]
for(i in pc) {
pca.img <- sapply(rgb.pca, function(j) {
compressed.img <- j$x[,1:i] %*% t(j$rotation[,1:i])
}, simplify = 'array')
writeJPEG(pca.img, paste('dog_pca_',i,'.jpg', sep = ''))
}
for(i in pc) {
pca.img <- sapply(rgb.pca, function(j) {
compressed.img <- j$x[,1:i] %*% j$rotation[,1:i]
}, simplify = 'array')
writeJPEG(pca.img, paste('dog_pca_',i,'.jpg', sep = ''))
}
# 분석, 결과치 확인 및 해석
# Standard deviation (표준 편차)의 제곱 = 분산 = eigenvalue
# Proportion of Variance : 각 주성분이 차지하는 분산 비율
# Cumulative Proportion : 분산의 누적 비율
summary(iris.pca)
ggplot(data = reduced_data, aes(x=PC1, y =PC2)) + geom_point(aes(color=tar, shape=tar)) + xlab("PC1") + ylab("PC2")+ggtitle("PCA DATA")
#####################
tar <- rawdata1[, target]
#####################
str(rawdata1)
#####################
tar <- rawdata1[, target]
#####################
tar <- rawdata1[ , target]
#####################
rawdata1[,target]
#####################
tar <- rawdata1[ , "target"]
reduced_data <- data.frame(cbind(pca_num$x[,1:3], tar))
reduced_data$tar <- as.factor(reduced_data$tar)
str(reduced_data)
library(ggplot2)
ggplot(data = reduced_data, aes(x=PC1, y =PC2)) + geom_point(aes(color=tar, shape=tar)) + xlab("PC1") + ylab("PC2")+ggtitle("PCA DATA")
ggplot(data = reduced_data, aes(x=PC1, y =PC2)) + geom_point(aes(color=tar, shape=tar)) +ggtitle("PCA DATA")
summary(pca_num)
